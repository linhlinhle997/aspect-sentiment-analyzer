{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30887,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Build Dataset","metadata":{}},{"cell_type":"code","source":"!pip install -q datasets==3.2.0\n\nfrom datasets import load_dataset\n\nds = load_dataset(\"thainq107/abte-restaurants\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-02-13T02:56:07.171693Z","iopub.execute_input":"2025-02-13T02:56:07.171998Z","iopub.status.idle":"2025-02-13T02:56:21.760714Z","shell.execute_reply.started":"2025-02-13T02:56:07.171970Z","shell.execute_reply":"2025-02-13T02:56:21.759948Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/454 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b26f694f05694a57a8718060271d65db"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00000-of-00001.parquet:   0%|          | 0.00/183k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e42312df54544abeaf0fe9b394cea46b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"test-00000-of-00001.parquet:   0%|          | 0.00/61.8k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1b1a5ed97c704e7ca8d94169daa9045a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/3602 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f538b68812dc49e9ae560d0c244e6b59"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/1119 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e94d2c6649544c87b8f3456862d6365a"}},"metadata":{}}],"execution_count":1},{"cell_type":"markdown","source":"## Tokenization","metadata":{}},{"cell_type":"code","source":"from transformers import AutoTokenizer\n\ntokenizer = AutoTokenizer.from_pretrained(\"distilbert/distilbert-base-uncased\")\n\ndef tokenize_and_align_labels(examples):\n    tokenized_inputs = []\n    labels = []\n\n    for tokens, tags in zip(examples['Tokens'], examples['Tags']):\n        # Clean and split tokens and tags\n        tokens = str(tokens).replace(\"’\", \"\").strip(\"][\").split(\", \")\n        tags = str(tags).strip(\"][\").split(\", \")\n        tags = [tag.strip(\"'\\\"\") for tag in tags]\n        \n        bert_tokens = []\n        bert_tags = []\n\n        for i in range(len(tokens)):\n            t = tokenizer.tokenize(tokens[i]) # Tokenize each token\n            bert_tokens += t\n            bert_tags += [int(tags[i])] * len(t) # Repeat the label for each sub-token\n\n        # Convert tokens to input IDs\n        bert_ids = tokenizer.convert_tokens_to_ids(bert_tokens)\n        tokenized_inputs.append(bert_ids)\n        labels.append(bert_tags)\n\n    return {\n        'input_ids': tokenized_inputs,\n        'labels': labels\n    }\n\n# Apply the tokenization and label alignment to the dataset\npreprocessed_ds = ds.map(tokenize_and_align_labels, batched=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T02:56:21.761643Z","iopub.execute_input":"2025-02-13T02:56:21.762024Z","iopub.status.idle":"2025-02-13T02:56:36.107050Z","shell.execute_reply.started":"2025-02-13T02:56:21.762002Z","shell.execute_reply":"2025-02-13T02:56:36.106345Z"}},"outputs":[{"name":"stderr","text":"The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"88bb12d42171432f8ee7eb5d43248d9d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"67e7277541944e799d52420cdd15aae1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"787a3de1d2a2421187a9ece64db113c0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1e06b997e86841c895d964ddbdd378b5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8a5a90d1a4e449f3824329b3b37432de"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/3602 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"663d216bc90847aabb098508bb96716e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1119 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"82e3cd6de47942ee9b6db801003a420b"}},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"preprocessed_ds.column_names","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T02:56:36.108911Z","iopub.execute_input":"2025-02-13T02:56:36.109130Z","iopub.status.idle":"2025-02-13T02:56:36.114477Z","shell.execute_reply.started":"2025-02-13T02:56:36.109111Z","shell.execute_reply":"2025-02-13T02:56:36.113631Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"{'train': ['Tokens', 'Tags', 'Polarities', 'input_ids', 'labels'],\n 'test': ['Tokens', 'Tags', 'Polarities', 'input_ids', 'labels']}"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"print(\"Input IDs:\", preprocessed_ds['train']['input_ids'][0])\nprint(\"Labels:\", preprocessed_ds['train']['labels'][0])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T02:56:36.115930Z","iopub.execute_input":"2025-02-13T02:56:36.116220Z","iopub.status.idle":"2025-02-13T02:56:36.345674Z","shell.execute_reply.started":"2025-02-13T02:56:36.116190Z","shell.execute_reply":"2025-02-13T02:56:36.344792Z"}},"outputs":[{"name":"stdout","text":"Input IDs: [1005, 2021, 1005, 1005, 1996, 1005, 1005, 3095, 1005, 1005, 2001, 1005, 1005, 2061, 1005, 1005, 9202, 1005, 1005, 2000, 1005, 1005, 2149, 1005, 1005, 1012, 1005]\nLabels: [0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"## Data Collator","metadata":{}},{"cell_type":"code","source":"from transformers import DataCollatorForTokenClassification\n\n# Create a data collator for token classification tasks\ndata_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T02:56:36.346516Z","iopub.execute_input":"2025-02-13T02:56:36.346978Z","iopub.status.idle":"2025-02-13T02:56:49.358512Z","shell.execute_reply.started":"2025-02-13T02:56:36.346935Z","shell.execute_reply":"2025-02-13T02:56:49.357855Z"}},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"## Evaluate","metadata":{}},{"cell_type":"code","source":"!pip install -q seqeval==1.2.2","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T02:56:49.359300Z","iopub.execute_input":"2025-02-13T02:56:49.359810Z","iopub.status.idle":"2025-02-13T02:56:55.598238Z","shell.execute_reply.started":"2025-02-13T02:56:49.359785Z","shell.execute_reply":"2025-02-13T02:56:55.597211Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"import numpy as np\nfrom seqeval.metrics import accuracy_score\n\ndef compute_metrics(p):\n    predictions, labels = p\n    predictions = np.argmax(predictions, axis=2)\n\n    # Extract true predictions by filtering out tokens with label -100 (ignored during padding).\n    true_predictions = [\n        [str(p) for (p, l) in zip(prediction, label) if l != 100]\n        for prediction, label in zip(predictions, labels)\n    ]\n\n    # Extract true labels by filtering out the ignored tokens (-100).\n    true_labels = [\n        [str(l) for (p, l) in zip(prediction, label) if l != -100]\n        for prediction, label in zip(predictions, labels)\n    ]\n\n    results = accuracy_score(true_predictions, true_labels)\n    return {\"accuracy\": results}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T02:56:55.599590Z","iopub.execute_input":"2025-02-13T02:56:55.599880Z","iopub.status.idle":"2025-02-13T02:56:55.614111Z","shell.execute_reply.started":"2025-02-13T02:56:55.599856Z","shell.execute_reply":"2025-02-13T02:56:55.613374Z"}},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"## Model","metadata":{}},{"cell_type":"code","source":"from transformers import AutoModelForTokenClassification\n\nid2label = {\n    0: \"O\",\n    1: \"B-Term\",\n    2: \"I-Term\"\n}\nlabel2id = {\n    \"O\": 0,\n    \"B-Term\": 1,\n    \"I-Term\": 2\n}\n\nmodel = AutoModelForTokenClassification.from_pretrained(\n    \"distilbert/distilbert-base-uncased\",\n    num_labels=3, id2label=id2label, label2id=label2id\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T02:56:55.617067Z","iopub.execute_input":"2025-02-13T02:56:55.617291Z","iopub.status.idle":"2025-02-13T02:56:59.369952Z","shell.execute_reply.started":"2025-02-13T02:56:55.617273Z","shell.execute_reply":"2025-02-13T02:56:59.369162Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4232fa0b43d44af0857ed7615d00b77b"}},"metadata":{}},{"name":"stderr","text":"Some weights of DistilBertForTokenClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":8},{"cell_type":"markdown","source":"## Training","metadata":{}},{"cell_type":"code","source":"import os\n\nos.environ[\"WANDB_DISABLED\"] = \"true\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T02:56:59.370885Z","iopub.execute_input":"2025-02-13T02:56:59.371108Z","iopub.status.idle":"2025-02-13T02:56:59.375117Z","shell.execute_reply.started":"2025-02-13T02:56:59.371088Z","shell.execute_reply":"2025-02-13T02:56:59.374089Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"from transformers import TrainingArguments, Trainer\n\ntraining_args = TrainingArguments(\n    output_dir=\"abte-restaurants-distilbert-base-uncased\",\n    learning_rate=2e-5,\n    per_device_train_batch_size=16,\n    per_device_eval_batch_size=16,\n    num_train_epochs=5,\n    weight_decay=0.01,\n    eval_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    load_best_model_at_end=True\n)\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=preprocessed_ds[\"train\"],\n    eval_dataset=preprocessed_ds[\"test\"],\n    processing_class=tokenizer,\n    data_collator=data_collator,\n    compute_metrics=compute_metrics\n)\n\ntrainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T02:56:59.376112Z","iopub.execute_input":"2025-02-13T02:56:59.376344Z","iopub.status.idle":"2025-02-13T03:00:12.836475Z","shell.execute_reply.started":"2025-02-13T02:56:59.376323Z","shell.execute_reply":"2025-02-13T03:00:12.835624Z"}},"outputs":[{"name":"stderr","text":"Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='565' max='565' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [565/565 03:08, Epoch 5/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>0.193533</td>\n      <td>0.196600</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>No log</td>\n      <td>0.149018</td>\n      <td>0.197288</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>No log</td>\n      <td>0.152572</td>\n      <td>0.196709</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>No log</td>\n      <td>0.165556</td>\n      <td>0.196773</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.120300</td>\n      <td>0.168672</td>\n      <td>0.196882</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=565, training_loss=0.11125038746183952, metrics={'train_runtime': 190.7199, 'train_samples_per_second': 94.432, 'train_steps_per_second': 2.962, 'total_flos': 730006263413100.0, 'train_loss': 0.11125038746183952, 'epoch': 5.0})"},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"trainer.save_model(\"abte-restaurants-distilbert-base-uncased\")\ntokenizer.save_pretrained(\"abte-restaurants-distilbert-base-uncased\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T03:07:15.471524Z","iopub.execute_input":"2025-02-13T03:07:15.471895Z","iopub.status.idle":"2025-02-13T03:07:16.146202Z","shell.execute_reply.started":"2025-02-13T03:07:15.471869Z","shell.execute_reply":"2025-02-13T03:07:16.145450Z"}},"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"('abte-restaurants-distilbert-base-uncased/tokenizer_config.json',\n 'abte-restaurants-distilbert-base-uncased/special_tokens_map.json',\n 'abte-restaurants-distilbert-base-uncased/vocab.txt',\n 'abte-restaurants-distilbert-base-uncased/added_tokens.json',\n 'abte-restaurants-distilbert-base-uncased/tokenizer.json')"},"metadata":{}}],"execution_count":12},{"cell_type":"markdown","source":"## Prediction","metadata":{}},{"cell_type":"code","source":"from transformers import pipeline\n\ntoken_classifier = pipeline(\n    \"ner\",\n    model=\"abte-restaurants-distilbert-base-uncased\",\n    tokenizer=\"abte-restaurants-distilbert-base-uncased\",\n    aggregation_strategy=\"simple\"\n)\n\ntest_sentence = \"The bred is top notch as well\"\nresult = token_classifier(test_sentence)\nresult","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T03:11:14.547075Z","iopub.execute_input":"2025-02-13T03:11:14.547507Z","iopub.status.idle":"2025-02-13T03:11:14.763520Z","shell.execute_reply.started":"2025-02-13T03:11:14.547468Z","shell.execute_reply":"2025-02-13T03:11:14.762666Z"}},"outputs":[{"name":"stderr","text":"Device set to use cuda:0\n","output_type":"stream"},{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"[{'entity_group': 'Term',\n  'score': 0.48610213,\n  'word': 'bred',\n  'start': 4,\n  'end': 8},\n {'entity_group': 'Term',\n  'score': 0.46678838,\n  'word': 'top',\n  'start': 12,\n  'end': 15}]"},"metadata":{}}],"execution_count":22}]}